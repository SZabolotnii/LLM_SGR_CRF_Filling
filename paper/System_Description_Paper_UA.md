# DocUA на CRF filling 2026: LLM StructCore — Конденсація міркувань на основі схеми та детермінована компіляція

**Сергій Заболотній**  
Черкаський державний бізнес-коледж  
Черкаси, Україна  
zabolotnii.serhii@csbc.edu.ua

---

## Анотація

Автоматичне заповнення Case Report Forms (CRF) на основі клінічних нотаток є складним завданням через зашумленість мови, суворі вихідні контракти та високу ціну хибнопозитивних результатів. Ми описуємо наше рішення для CL4Health 2026 із заповнення Dyspnea CRF (134 пункти), що використовує *контрактно-керовану* двостадійну архітектуру, побудовану на базі *Schema-Guided Reasoning* (SGR) [abdullin2026sgr]. Ключовою властивістю завдання є **екстремальна розрідженість**: більшість полів мають значення `unknown`, а офіційне оцінювання карає як за порожні значення, так і за непідтверджені прогнози. Ми переходимо від одностадійного підходу «LLM прогнозує 134 поля» до декомпозиції, де:
(i) Етап 1 створює стабільне SGR-подібне JSON-резюме з точно 9 доменними ключами, та
(ii) Етап 2 — це повністю детермінований компілятор (0-LLM), який аналізує резюме Етапу 1, канонізує назви пунктів (опціонально використовуючи карту UMLS-псевдонімів з покриттям 134/134), нормалізує прогнози до офіційного контрольованого словника (13 категорій), застосовує фільтри хибнопозитивних результатів на основі доказів та розгортає вивід у необхідний формат із 134 пунктів.
На вибірці dev80 найкраща конфігурація вчителя (Mistral Large 3 Етап 1 → детермінований Етап 2) досягає macro-F1 **0.6543** (EN) та **0.6905** (IT); на закритому тесті test200 поданий англійський варіант набирає **0.63** на Codabench. Пайплайн є мовно-агностичним: результати для італійської відповідають або перевищують англійські без жодної мовно-специфічної інженерії.

**Ключові слова:** клінічна NLP, вилучення інформації, schema-guided reasoning, контрольований словник, відтворюваність, edge AI

---

## 1. Вступ

Завдання CL4Health 2026 із заповнення CRF вимагає відображення неструктурованих клінічних нотаток на суворий 134-пунктовий Dyspnea CRF. На практиці наскрізне LLM-вилучення часто зазнає невдачі або через дрейф формату виводу (невалідна JSON/JSONL структура), або через непідтверджені «галюциновані» заповнення, що збільшують кількість хибнопозитивних результатів (FP). Наша мета — розділити **(а)** конденсацію клінічної інформації від **(б)** забезпечення виконання контракту та нормалізації контрольованого словника, використовуючи SGR для створення стабільного проміжного представлення, що піддається машинній перевірці.

### Schema-Guided Reasoning (SGR)
SGR [abdullin2026sgr] — це архітектурний патерн, який обмежує LLM створювати типізовані, відповідні схемі виходи через structured output або constrained decoding [dong2024xgrammar, willard2023], перетворюючи доменні знання на виконувані контракти даних. Це зменшує варіативність і покращує надійність порівняно з вільноформатними текстовими промптами. У нашій системі Етап 1 використовує SGR-схему з трьома основними патернами для створення стабільного 9-ключового доменного резюме:

- **Каскад (Доменний каркас):** LLM дотримується фіксованої послідовності з 9 клінічних доменів (Demographics → Vitals → Labs → Problems → Symptoms → Medications → Procedures → Utilization → Disposition) для забезпечення рівномірного покриття клінічного наративу.
- **Цикл (Чек-листи):** Промпт впроваджує неявні чек-листи в кожному домені (наприклад, перевірка 28 конкретних проблем CRF, усіх критичних вітальних знаків) для покращення recall на розріджених пунктах.
- **Маршрутизація (Словник):** Хоча Етап 1 видає необмежені текстові рядки в межах JSON-структури, Етап 2 детерміновано маршрутизує кожен прогноз в одну з 13 необхідних категорій контрольованого словника (Таблиця 1).

Етап 2 потім детерміновано компілює це резюме в офіційний формат подачі CRF, забезпечуючи 100% структурну відповідність.

---

## 2. Завдання та дані

### 2.1 Набори даних та спліти
Ми використовуємо офіційні набори даних Hugging Face [ferrazzi2025converting] (`NLP-FBK/dyspnea-crf-*`) та, для генерації даних вчителя, набір неанотованих клінічних нотаток у домені (`NLP-FBK/dyspnea-clinical-notes`, 2,667 записів з лікарні SGB, Італія). Train містить 10 анотованих записів, development — 80, test — 200 (прихована ground truth).

Ключовим відкриттям є **екстремальна розрідженість**: у розробницькому наборі медіанна кількість non-`unknown` пунктів на документ становить лише ~12 із 134 загальних. Найчастішими non-unknown пунктами є VITALS (*heart rate*, *blood pressure*, *spo2*) та LABS (*hemoglobin*, *creatinine*), тоді як багато діагнозів та процедур з'являються менш ніж у 5% документів. Ця розрідженість означає, що `unknown` — найпоширеніший клас, і правильне прогнозування `unknown` для відсутніх пунктів є настільки ж важливим, як і правильне вилучення наявних значень.
Офіційний scorer [ferrazzi2026] використовує macro-F1 по пунктах, що суворо карає як хибнопозитивні (FP: прогнозування значення для `unknown` пункту), так і хибнонегативні (FN: прогнозування `unknown` для наявного пункту) результати.

### 2.2 Контрактний парсинг даних
Ми узгоджуємо контракти нашого пайплайну безпосередньо зі схемою набору даних:
(i) впорядкований список із 134 пунктів інферується з `annotations[*].item` та використовується наскрізно;
(ii) ідентифікатори документів нормалізуються до plain ID (префікс перед першим підкресленням) для внутрішнього узгодження, а суфікс мовного тегу (`_en`/`_it`) додається лише для фінальних подач;
(iii) проміжні представлення є розрідженими, але фінальний builder завжди розгортає до всіх 134 пунктів, заповнюючи відсутні значення як `unknown`.

---

## 3. Огляд системи

Наш пайплайн дотримується суворої двостадійної декомпозиції:

```
Clinical Note → Stage 1 (LLM, SGR JSON) → Stage 2 (0-LLM compiler) → Submission.jsonl
```

### Рисунок 1. Архітектура двостадійного пайплайну LLM StructCore

```
┌──────────────────────┐
│   Клінічна нотатка   │
│     (en / it)        │
└──────────┬───────────┘
           │
           ▼
┌──────────────────────┐     SGR Contract:
│  Етап 1 (LLM)       │     - Cascade: послідовність 9 доменів
│  SGR JSON            │     - Cycle: чек-листи по кожному домену
│  (9 ключів)          │     - Тільки підтверджені факти
└──────────┬───────────┘     - JSON parse: 100% стабільний
           │
           ▼
┌──────────────────────┐     4-кроковий алгоритм:
│  Етап 2 (0-LLM)     │     1. Вилучення KV
│  Детермінований      │     2. Канонізація + UMLS
│  компілятор          │     3. FP-фільтри та виведення
└──────────┬───────────┘     4. Нормалізація словника (13 кат.)
           │
           ▼
┌──────────────────────┐
│   Подача             │
│   (134 пункти)       │
└──────────────────────┘
```

*Етап 1 конденсує клінічну нотатку в 9-ключовий SGR JSON; Етап 2 детерміновано компілює його в 134-пунктову подачу.*

### 3.1 Етап 1: SGR-резюме у форматі JSON

Етап 1 створює об'єкт JSON з точно 9 доменними ключами: `DEMOGRAPHICS`, `VITALS`, `LABS`, `PROBLEMS`, `SYMPTOMS`, `MEDICATIONS`, `PROCEDURES`, `UTILIZATION`, `DISPOSITION`.

Резюме спроектоване як **розріджене** (включає лише факти, підтверджені доказами) та **стабільне за форматом** (успішний JSON parse на кожному вході). На спліті train10 ми спостерігаємо `json_parse_ok=10/10` та `thinking_leak=0/10` навіть на квантованих 4B моделях через `llama.cpp` без граматично обмеженого декодування.

**Структура промпту.** Промпт Етапу 1 інструктує модель створити один JSON-об'єкт за суворим шаблоном. Кожен із 9 ключів відповідає текстовому рядку, що підсумовує відповідний клінічний домен. Промпт включає:
(i) явні визначення обсягу кожного ключа (наприклад, `PROBLEMS` охоплює минулу медичну історію, `SYMPTOMS` — поточні скарги);
(ii) чек-лист пріоритетних пунктів по кожному домену (наприклад, 28 конкретних проблем з CRF-онтології, усі вітальні знаки, ключові лабораторні показники);
(iii) інструкції з форматування `Key: Value` для машинного парсингу;
(iv) директиву розрідженості: «включайте лише факти, явно зазначені в нотатці; не виводьте та не вгадуйте».
Ця структурована архітектура промпту реалізує SGR-патерни Cascade та Cycle, забезпечуючи систематичне покриття та запобігаючи галюцинованим заповненням.

**Стабільність формату без обмеженого декодування.** Важливим висновком є те, що наш SGR-промпт досягає 100% успіху парсингу JSON *без* використання граматично обмеженого декодування (наприклад, XGrammar [dong2024xgrammar] або Outlines [willard2023]). Ми пояснюємо це простотою цільової схеми (плоский об'єкт з 9 ключами та рядковими значеннями) та явними інструкціями з форматування. Це робить підхід сумісним з будь-яким бекендом інференсу (`llama.cpp`, vLLM, OpenAI-compatible APIs, Gemini Vertex) без підтримки граматик на стороні бекенду.

**Стратегія Multi-Slice.** Довгі клінічні нотатки можуть перевищувати ефективне контекстне вікно моделі. Ми реалізуємо стратегію **multi-slice**: нотатка розбивається на вікна з перекриттям (наприклад, `middle+head_tail`, розмір вікна w=4), кожне вікно підсумовується незалежно через Етап 1, а результати JSON-об'єктів зливаються за принципом last-writer-wins по кожному ключу. Для ключів `PROBLEMS`, `MEDICATIONS` та `LABS` (які накопичують множинні факти) ми конкатенуємо рядки з усіх вікон замість перезапису. Це зберігає recall для фактів, розсіяних по нотатці, утримуючи кожен окремий інференс у межах контексту.

**Генерація даних вчителя.** Для пайплайну вчителя Етапу 1 ми використовуємо великі API-доступні моделі для створення високоякісних SGR-резюме. Ми протестували три конфігурації вчителя:
- **Mistral Large 3** (675B, через NVIDIA API) — найкраща загальна якість, підтримує `response_format=json_object` на більшості NVIDIA-ендпоінтів (з автоматичним фолбеком на парсер для Mistral-моделей, де structured output повертає помилки 400).
- **Qwen 3.5** (397B, через NVIDIA API) — порівнянна якість, але вищий FP; потребує `enable_thinking=false` для запобігання витоку «Thinking Process» у вивід.
- **Claude Sonnet 4.6** (через Anthropic API) — recall-оптимізовані промпти дають сильні результати, але не подані через ліміти участі.

Резюме, згенеровані вчителем, компілюються через той самий детермінований Етап 2, що дозволяє точне ablation-порівняння якості Етапу 1 проти детермінованої логіки Етапу 2.

**Конкретний приклад.** Для SGR JSON з `VITALS: "Heart Rate: 105 bpm (tachycardic). Blood Pressure: 90/60 mmHg (hypotensive). SpO2: 88%. Respiratory Rate: 28/min (tachypneic)."` компілятор Етапу 2:
1. Вилучає KV-пари: {*heart rate*: "105 bpm (tachycardic)", *blood pressure*: "90/60 mmHg (hypotensive)", *spo2*: "88%", *respiratory rate*: "28/min (tachypneic)"}.
2. Канонізує: всі ключі збігаються з офіційним списком пунктів.
3. FP-фільтри не спрацьовують для вітальних знаків.
4. Нормалізує: *heart rate* → `tachycardic`, *blood pressure* → `hypotensive`, *spo2* → `88`, *respiratory rate* → `tachypneic`.

Решта 130 пунктів заповнюються як `unknown`.

### 3.2 Етап 2: Детермінований компілятор (0-LLM)

Етап 2 **не робить жодних викликів LLM**. Він реалізує 4-кроковий детермінований алгоритм:

**Крок 1: Вилучення KV.** Парсинг тексту резюме Етапу 1 у плоський словник пар `(назва_пункту, рядок_значення)` шляхом збігу рядків `Key: Value` у кожній доменній секції. Рядки зі значеннями `not stated` або `unknown` пропускаються.

**Крок 2: Канонізація.** Нормалізація назв пунктів через: (а) точний збіг з офіційним списком 134 пунктів; (б) приведення до нижнього регістру та видалення пунктуації (наприклад, `first episode` → `first episod`); (в) розширення абревіатур (70+ правил, наприклад `hr` → `heart rate`, `cxr` → `chest rx`); (г) опціонально, UMLS alias resolution з використанням кураторської карти з **покриттям 134/134** [aronson2001].

**Крок 3: FP-ворота та деривація.** Виведення складених пунктів з високим FN з доказів Етапу 1: *poly-pharmacological therapy* інферується при ≥8 різних медикаментах; *antihypertensive therapy* виявляється зіставленням з 35 антигіпертензивними агентами; *cardiovascular diseases* виводиться з терапевтичних прапорців або ключових слів PMH. Потім суворі regex-ворота **відкидають** непідтверджені позитивні прогнози для пунктів з високою ціною FP: *active neoplasia* (потребує онкологічної лексики + маркерів активності), *arrhythmia* (потребує специфічних ритмічних термінів, блокується при `NSR`), *acute coronary syndrome* (потребує ACS-лексики + підтверджуючих доказів), *presence of dyspnea* (блокується при явній негації).

**Крок 4: Нормалізація словника (13 категорій).** Відображення кожного рядка значення на офіційний контрольований словник (Таблиця 1): binary → `y/n`; AVPU → `A/V/P`; хронічні пункти → 4-класова шкала; neoplasia → 3-класова активність; тривалість → `short/long`; вітальні знаки → категоріальні (наприклад, `tachycardic/normocardic/bradycardic`); лабораторні → числове вилучення або `measured`. Нарешті, розгортання до всіх 134 пунктів із заповненням відсутніх як `unknown`.

### Таблиця 1: 13 категорій контрольованого словника, визначених CRF-онтологією

| # | Категорія словника | Пунктів |
|---:|---|---:|
| 1 | chronic (4-class) | 7 |
| 2 | neoplasia (3-class) | 1 |
| 3 | duration (short/long) | 2 |
| 4 | binary (y/n) | 61 |
| 5 | mobility (4-class) | 1 |
| 6 | consciousness (AVPU) | 1 |
| 7 | respiratory rate (3-cat) | 1 |
| 8 | body temperature (3-cat) | 1 |
| 9 | heart rate (3-cat) | 1 |
| 10 | blood pressure (3-cat) | 1 |
| 11 | respiratory distress (current/past) | 1 |
| 12 | diagnostic tests (pos/neg) | 4 |
| 13 | labs (measured/numeric) | 25 |
| | **Всього** | **107** |
| | Unknown-only залишок | 27 |
| | **Загалом** | **134** |

*Етап 2 відображає кожен вилучений рядок значення точно в одну з цих категорій.*

### 3.3 Опціональне UMLS Alias Mapping
Ми створили UMLS-карту псевдонімів для всіх 134 пунктів CRF (**покриття 134/134**) та інтегрували її як опціональний режим пайплайну (`--use-umls-mapping`) для зменшення крихкості назв ключів у виводах моделей. Карта пов'язує кожну офіційну назву пункту з її UMLS CUI та preferred name, плюс вручну верифіковані синоніми. Цей режим активований у всіх фінальних подачах.

---

## 4. Експерименти та результати

Ми звітуємо результати на трьох масштабах: train10 (для дебагу), dev80 (відкритий GT, використовується як «sanity gate» перед подачею), та test200 (Codabench, прихований GT).

### 4.1 Результати розробки (dev80, відкритий GT)

Таблиця 2 підсумовує наші основні запуски на dev80 для англійської та італійської мов. Усі використовують однаковий детермінований компілятор Етапу 2 з UMLS mapping та FP-воротами; EN-запуски використовують `rules_v3a`, тоді як останній IT-варіант використовує покращений `rules_v3e`.

### Таблиця 2: Основні результати на dev80 та ablation на train10

| Мова | Модель Етапу 1 | F1 | TP | FP | FN |
|---|---|---:|---:|---:|---:|
| EN | Mistral Large 3 (675B) | 0.6543 | 236 | 170 | 128 |
| IT | Mistral Large 3 (v3e) | **0.6905** | 266 | 198 | 106 |
| IT | Mistral Large 3 (v3a) | 0.6900 | 266 | 201 | 106 |
| EN | Qwen 3.5 (397B, think=off) | 0.6411 | 236 | 211 | 128 |
| | *Менш масштабні ablation (train10):* | | | | |
| EN | Gemini Flash (teacher) | 0.6763 | 68 | 35 | 9 |
| EN | MedGemma 4B (student) | 0.6521 | 57 | 13 | 22 |
| EN | SGR-only baseline | 0.4384 | 39 | 44 | 39 |

*Усі варіанти використовують однаковий детермінований компілятор Етапу 2. `v3e` — останній набір правил з покращеними FP-drop воротами для IT. F1 = офіційний macro-F1; TP/FP/FN = кількість по пунктах.*

**Ключові спостереження.**
(1) Mistral Large 3 та Qwen 3.5 мають порівнянну кількість TP (236) для EN, але Qwen генерує більше FP (211 проти 170), ймовірно через менш консервативне резюмування.
(2) Кількість FN однакова (128) для обох EN-моделей вчителя, що вказує на стелю детермінованих правил виведення Етапу 2, *обмежену recall-ом Етапу 1*.
(3) На train10 вчительський Етап 1 (Gemini) різко зменшує FN (9 проти 22 для студента), але збільшує FP (35 проти 13), мотивуючи наші evidence-gated FP-фільтри.
(4) Студентська модель (MedGemma 4B, локальна) досягає F1=0.6521 на train10 з дуже низьким FP (13), що свідчить про більш консервативне резюмування менших моделей.
(5) Італійський dev80 досягає вищого F1 (0.6905) ніж англійський (0.6543) з більшою кількістю TP (266 проти 236) та меншим FN (106 проти 128), що вказує на більш структуровані оригінальні італійські нотатки.
Набір правил `v3e` зменшує 3 FP порівняно з `v3a` (198 проти 201) через суворіші FP-drop ворота для *chest pain*, *heart failure* та *arrhythmia*.

**Ablation multi-slice.** Обидва запуски вчителя на dev80 використовують стратегію `middle+head_tail` з w=4. Порівняно з одновіконними запусками, multi-slice відновлює +12–18 додаткових TP ціною +8–15 FP — чистий позитивний результат. Покращення зосереджене в доменах `LABS` та `MEDICATIONS`, де інформація часто розкидана по нотатці.

### 4.2 Тестові результати (Codabench)

Таблиця 3 показує подані та оцінені результати test200 разом з контекстом лідерборду.

### Таблиця 3: Результати Test200 на Codabench

| Варіант системи | F1 | Мова | Команда | Статус |
|---|---:|---|---|---|
| Mistral L3 → Stage2(det) | 0.63 | EN | DocUA | Подано |
| No FP-gates variant | 0.61 | EN | DocUA | Подано |
| Claude Sonnet → Stage2(det) | 0.62 | EN | DocUA | Оцінено† |
| Mistral L3 recall (v3e) | --- | IT | DocUA | Підготовлено‡ |

*Усі варіанти DocUA використовують детермінований Етап 2 + UMLS mapping. †Оцінено, але не подано як фінальний варіант через ліміти участі. ‡Італійський варіант підготовлено (Stage 1 SGR9 recall, chars=8000, multi-slice, `rules_v3e`), але не подано через вичерпання спроб.*

Найкраща подана англійська система досягає F1=0.63 з Mistral Large 3 як вчитель Етапу 1, що на 0.05 від топового результату (F1=0.68). Варіант Anthropic (Claude Sonnet 4.6 з recall-оптимізованими промптами) показує порівнянну якість (F1=0.62), але не подавався як фінальний варіант через ліміт участі. Італійський варіант з `rules_v3e` був повністю підготовлений (dev80 IT F1=0.6905), але не міг бути поданим — усі спроби вичерпані.

Наші висновки вказують, що великі open-weight моделі типу Mistral створюють резюме Етапу 1, конкурентні з більшими пропрієтарними системами.

**Крос-мовна валідація Dev10.** Для підтвердження крос-мовної стійкості ми оцінили на малій вибірці dev10 для EN та IT з Anthropic Етап 1:

### Таблиця 4: Крос-мовна валідація dev10

| Мова | F1 | TP | FP | FN |
|---|---:|---:|---:|---:|
| Italian (IT) | **0.9000** | 59 | 9 | 4 |
| English (EN) | 0.8115 | 55 | 18 | 7 |

*(Anthropic recall Етап 1 → Етап 2 det)*

Результати для італійської помітно вищі, ніж для англійської на цій малій вибірці. Ця тенденція **підтверджена на масштабі dev80**: IT F1=0.6905 проти EN=0.6543 (Таблиця 2). Ми пов'язуємо це з двома факторами: (1) італійські клінічні нотатки з лікарні SGB написані більш структурованим, формульним стилем, ніж їхні англійські переклади, що полегшує чистіше вилучення Етапом 1; (2) деякі пункти CRF використовують італійську медичну термінологію, що безпосередніше відображається на онтологію (наприклад, *dispnea* → *presence of dyspnea*).

### 4.3 Аналіз помилок

**Ефективність FP-воріт.** Механізм FP-воріт (Крок 3 Етапу 2) відкидає в середньому 3.2 пункти на документ, що інакше були б хибнопозитивними. Таблиця 5 показує попунктовий вплив FP-воріт на dev80.

### Таблиця 5: Ефективність FP-воріт на dev80 EN (Mistral Large 3)

| Пункт з воротами | FP до | FP після |
|---|---:|---:|
| active neoplasia | 18 | 4 |
| arrhythmia | 12 | 5 |
| acute coronary syndrome | 9 | 2 |
| presence of dyspnea | 7 | 3 |
| **Всього (пункти з воротами)** | **46** | **14** |

*Ворота зменшують FP для високоризикових пунктів на ~70%, зберігаючи TP.*

Найбільший вплив мають ворота для *active neoplasia*: без evidence gating доброякісні згадки типу «cancer screening» чи «family history of cancer» створюють FP; ворота потребують явної онкологічної лексики *плюс* маркерів активності (наприклад, «chemotherapy», «progression», «untreated»). Для *arrhythmia* ворота блокують позитивні прогнози, коли докази містять Normal Sinus Rhythm (`NSR`), запобігаючи поширеній помилковій класифікації ЕКГ-описаних пацієнтів.

**Італійсько-специфічні патерни помилок (dev80 IT).** Детальна попунктова діагностика на спліті dev80 IT (Mistral Large 3 → `rules_v3e`) виявляє як спільні, так і мовно-специфічні патерни помилок. Топ джерел FN: *foreign body in the airways* (11 FN, Етап 1 ніколи не поверхує цей пункт), *presence of dyspnea* (7 FN / 8 FP — напруга між покриттям та FP), *diffuse vascular disease* (7 FN / 6 FP), *agitation* (7 FN, не вилучається Етапом 1). Топ джерел FP: *chest pain* (13 FP), *cardiovascular diseases* (13 FP — спрацьовує правило деривації від терапевтичних прапорців), *level of consciousness* (9 FP — помилки AVPU mapping), *heart failure* (8 FP — «PMH: HF» в Етапі 1 часто створює FP, коли GT = `unknown`).

Порівняння профілів помилок EN та IT dev80: обидві мови мають однакову стелю FN на рідкісних станах (*foreign body*, *agitation*), підтверджуючи, що це обмеження recall Етапу 1, незалежні від мови. Однак проблема FP для *chest pain* серйозніша в IT (13 FP проти EN), ймовірно тому, що італійські нотатки використовують термін *dolore toracico* в ширших клінічних контекстах.

**Залишкові FN-помилки.** Домінуючий тип помилок — **FN Етапу 1**: пункти, не згадані в резюме Етапу 1, не можуть бути відновлені детермінованим Етапом 2. Пункти з високим FN поділяються на три категорії:
- **Рідкісні стани:** *foreign body in the airways* (11 FN в IT), *cardiac tamponade*, *aortic dissection* — з'являються менш ніж у 5% нотаток і майже ніколи не поверхуються Етапом 1.
- **Неявні згадки:** *ab ingestis pneumonia*, *thoracic ultrasound* (6 FN в IT), *compression ultrasound (CUS)* — потребують доменно-специфічного розпізнавання, яке SGR-каскад може пропустити при конденсації.
- **Контекстно-залежні пункти:** *presence of dyspnea* (7 FN + 8 FP в IT), *level of consciousness* (6 FN + 9 FP в IT) — потребують нюансованого темпорального або категоріального міркування, яке важко закодувати у плоскому форматі Key:Value.

---

## 5. Обговорення

### 5.1 Ефективність SGR-декомпозиції
Застосування SGR переносить тягар структурної коректності з промпт-інженерії на код. Завдяки тому, що LLM видає стабільне 9-ключове проміжне дерево замість прямого створення 134 структурованих полів, ми досягаємо **100% стабільності парсингу JSON** навіть на квантованих 4B edge-моделях без граматично обмеженого декодування. Це примітно, оскільки пряме вилучення 134 полів тією ж 4B-моделлю не створює валідний JSON у >30% випадків у наших попередніх тестах.

SGR-декомпозиція також створює природний **кордон дебагу**: коли система видає некоректний прогноз, ми можемо негайно визначити, чи помилка виникла на Етапі 1 (факт не було вилучено), чи на Етапі 2 (факт вилучено, але неправильно відображено). На практиці >85% помилок — це FN Етапу 1, що підтверджує: детермінований компілятор не є вузьким місцем.

### 5.2 Детермінований проти LLM-базованого Етапу 2
Наші експерименти послідовно показують, що детермінований компілятор Етапу 2 перевершує LLM-базоване вилучення Етапу 2 в цьому settings. Ми протестували LLM-базований варіант Етапу 2 (використовуючи Anthropic Claude для прямого вилучення 134 пунктів з резюме Етапу 1) і виявили, що він:
- вводить дрейф словника (наприклад, видає `present` замість `y`, `yes` замість `certainly chronic`);
- створює непослідовні FP-патерни між запусками (недетерміновано);
- потребує додаткової постобробки для досягнення формальної відповідності;
- має нетривіальну вартість інференсу ($0.01–0.03 за документ через API).

Детермінований компілятор, навпаки, досягає ідеальної відповідності словнику, є повністю пояснюваним (кожне заповнення трасується до рядка Етапу 1 плюс конкретного правила), має нульову вартість інференсу та гарантує побітову відтворюваність.

### 5.3 SGR для Edge AI
Ця методологія особливо корисна для **edge (локальних) розгортань**. Великі state-of-the-art моделі можуть обробити 134 пункти за один прохід, але квантовані 4B–8B локальні моделі втрачають відстеження схеми виводу під час генерації. Наша SGR-конденсація вписується в межі міркувань менших моделей (9-ключовий JSON — це ~400 токенів), безпечно делегуючи складні перевірки словника та попунктову компіляцію детермінованому Python-коду. Це робить підхід практичним для privacy-preserving клінічних розгортань, де надсилання даних пацієнтів до зовнішніх API неприйнятне. Одночасна робота [ferrazzi2026smallllms] підтверджує, що малі LLM (~1B параметрів) можуть зрівнятися або перевершити великі базові моделі в італійських медичних NLP-завданнях — включаючи CRF filling — при використанні відповідних стратегій адаптації, таких як few-shot prompting та constraint decoding.

Конкретно, ми запускаємо MedGemma 1.5-4B-it як Q5\_K\_M GGUF через `llama.cpp` на Apple M3 Pro (18 ГБ RAM). Інференс Етапу 1 займає ~8 секунд на документ; компіляція Етапу 2 миттєва (<10 мс). Вся оцінка dev80 завершується менше ніж за 12 хвилин на одному ноутбуці.

### 5.4 Крос-мовна застосовність
Пайплайн природно поширюється на італійські (`_it`) документи: промпт Етапу 1 є мовно-агностичним (він просить модель вилучити клінічні факти незалежно від мови), а детермінована канонізація Етапу 2 обробляє мультимовні варіанти назв пунктів через UMLS alias map. Ми підготували італійські тестові подачі, використовуючи той самий пайплайн без мовно-специфічних модифікацій, окрім варіанту `rules_v3e` Етапу 2 (який додає суворіші FP-drop ворота для італійсько-специфічних хибнопозитивних патернів на *chest pain*, *heart failure* та *arrhythmia*).

Крос-мовні результати послідовно надають перевагу італійській на всіх масштабах оцінки:
dev10 (Таблиця 4): IT F1=0.90 проти EN F1=0.81;
dev80 (Таблиця 2): IT F1=0.6905 проти EN F1=0.6543.
Це вказує, що оригінальні італійські клінічні нотатки з лікарні SGB є більш структурованими та використовують більш формульне фразування, ніж їхні англійські переклади, що полегшує вилучення клінічних фактів SGR-промптом.
Примітно, що на лідерборді Codabench загальна top-1 система (Aurum) також досягає дуже подібних балів між мовами (EN 0.68, IT 0.67), що вказує: розрив EN–IT може бути меншим на масштабі з потужнішими системами.

### 5.5 Обмеження 9-ключової конденсації
Вибір саме 9 доменних ключів представляє компроміс. Менше ключів (наприклад, 3–4) ще більше спростили б Етап 1, але втратили б доменну організацію, ускладнюючи канонізацію Етапу 2. Більше ключів (наприклад, 20+) збільшили б recall, але наблизились би до складності прямого вилучення 134 пунктів, нівелюючи переваги стабільності. Ми експериментували з 5, 9 та 15 ключами (параметр «profile») і виявили, що 9 ключів забезпечують найкращий баланс стабільності Етапу 1 та recall Етапу 2.

---

## 6. Пов'язані роботи

Вилучення клінічної інформації має довгу історію — від правил до сучасних LLM-підходів. Конкурси i2b2/VA [uzuner2011] та завдання ShARe/CLEF eHealth [suominen2013] встановили ключові бенчмарки клінічної NLP для структурованого вилучення інформації з неструктурованого клінічного тексту. Нещодавно великі мовні моделі продемонстрували здатність кодувати суттєві клінічні знання [singhal2023], а доменно-специфічні моделі типу Med-Gemini [saab2024] досягають сильних результатів у медичних Q&A та клінічному reasoning.

**Структурована генерація.** Кілька фреймворків вирішують проблему стабільності виводу в LLM-вилученні. Constrained decoding [willard2023] впроваджує граматичні обмеження під час генерації токенів. SGLang [zheng2024] забезпечує програмний контроль над виконанням LLM з RadixAttention для ефективного структурованого виводу. XGrammar [dong2024xgrammar] пропонує гнучкий рушій для grammar-constrained генерації. Наш підхід є комплементарним: замість обмеження токенового виводу LLM ми спрощуємо цільову схему (9 ключів замість 134) та відкладаємо структурну відповідність на детермінований постпроцесор. Це уникає обчислювальних витрат та бекенд-залежності constrained decoding, досягаючи порівнянної стабільності виводу.

**Compiler-based LLM Pipelines.** DSPy [khattab2023] ввів концепцію компіляції декларативних програм мовних моделей у оптимізовані пайплайни. Наша система поділяє філософію «компіляції»: Етап 1 можна розглядати як декларативний крок вилучення, а Етап 2 — як компілятор, що трансформує проміжне представлення в цільовий формат. Однак наш Етап 2 повністю написаний вручну (детермінований), уникаючи потреби в оптимізаційних даних або мета-навчанні.

**Ontology Grounding.** UMLS-нормалізація концептів через MetaMap [aronson2001], QuickUMLS [soldaini2016] та ScispaCy [neumann2019] широко застосовується для розпізнавання біомедичних концептів.

Наша робота відрізняється явною двостадійною декомпозицією з повністю детермінованим Етапом 2, використанням SGR-патернів для стабільності проміжного представлення та акцентом на edge-deployable захисті конфіденційності. Одночасно [ferrazzi2026smallllms] представляють систематичне порівняння стратегій адаптації для малих LLM в італійській медичній NLP, охоплюючи 20 завдань включаючи CRF filling, та демонструючи, що fine-tuned 1.7B моделі можуть перевершити 32B базові моделі.

---

## 7. Висновок

LLM StructCore акцентує на контрактній відповідності, стабільності формату та відтворюваній пост-обробці для CRF filling в умовах екстремальної розрідженості. Двостадійна SGR-декомпозиція ізолює клінічне вилучення (Етап 1, будь-яка LLM) від суворого забезпечення подачі (Етап 2, детермінований), дозволяючи швидку ітерацію на recall Етапу 1 та заземлення контрольованого словника без жертвування детермінованими гарантіями виводу. Наша найкраща подана система досягає F1=0.63 на тестовому наборі Codabench (EN), що на 0.05 від top-1 команди (Aurum, F1=0.68). Пайплайн є повністю мовно-агностичним: італійський dev80 досягає F1=0.6905 без мовно-специфічних модифікацій Етапу 1, а італійська подача test200 була підготовлена (але не подана через вичерпання лімітів спроб). Це демонструє, що комбінація SGR-конденсації та детермінованої компіляції є конкурентною між мовами, пропонуючи повну відтворюваність та готовність до edge-розгортання.

Майбутня робота зосередиться на:
(i) покращенні recall Етапу 1 для пунктів з високим FN через доменно-специфічні чек-листи та few-shot приклади;
(ii) дослідженні гібридних підходів Етапу 2, що поєднують детерміновані правила з легковаговим LLM-інференсом для контекстно-залежних пунктів;
(iii) оцінці пайплайну на додаткових CRF-схемах та клінічних доменах за межами диспное.

---

## 8. Обмеження

Детермінований Етап 2 **не може відновити факти, відсутні в резюме Етапу 1**; таким чином, загальний recall обмежений Етапом 1. Деякі пункти CRF потребують нюансованої контекстуальної інтерпретації (наприклад, розрізнення «минулого» та «поточного» respiratory distress), яка може бути втрачена при 9-ключовій конденсації, збільшуючи ризик FN. Висока ціна FP завдання потребує консервативного evidence gating, що обмінює recall на precision у прикордонних випадках.

Канонізація на основі абревіатур спирається на вручну кураторський список 70+ абревіатур. Нові абревіатури або нетрадиційні написання, відсутні в карті, не будуть збігатися. UMLS alias map пом'якшує це, але також є статичною і може не покривати всі варіанти, згенеровані моделлю.

Regex-патерни FP-воріт є англо-центричними; хоча італійські нотатки в цьому наборі даних клінічно структуровані і переважно використовують міжнародну термінологію, розширення воріт для повного покриття італійського медичного словника потребує додаткової курації.

Нарешті, наша оцінка обмежена офіційними даними CL4Health 2026; узагальнення на інші CRF-схеми, клінічні домени або мови за межами англійської та італійської не тестувалося.

---

## 9. Відтворюваність

Вся детермінована логіка міститься в open-source пакеті `llm_structcore`. Код буде наданий у додаткових матеріалах та відкритий при прийнятті статті (Anonymous Repository). Репозиторій включає:
- Пакет `llm_structcore` (шаблони промптів Етапу 1, компілятор Етапу 2, scoring, submission builder).
- Скрипти для наскрізного інференсу на різних бекендах (`llama.cpp`, OpenAI-compatible APIs, HF Transformers, NVIDIA API, Gemini Vertex, Anthropic).
- Повну UMLS alias map (`data/umls_crf_mapping.json`, покриття 134/134).
- Визначення CRF-онтології (`data/ontology_crf_cl4health2026.md`).
- Скрипти оцінки від організаторів (`external/CRF-filling-CL4Health2026/`).
- Цю системну статтю (LaTeX source).

SGR-схема Етапу 1 гарантує `json_parse_ok=100%` з MedGemma 1.5-4B без потреби JSON-mode sampling. Етап 2 є повністю відтворюваним: те саме резюме Етапу 1 завжди дає ту саму 134-пунктову подачу, незалежно від платформи, версії Python чи порядку виконання.

---

## 10. Етичні міркування

Ми використовуємо публічно доступні набори даних згідно з умовами організаторів. Жодних приватних клінічних даних, окрім тих, що розповсюджуються shared task, не включено. Коли API-моделі вчителя використовуються для генерації даних, передаються резюме (не сирі нотатки); тим не менш, відповідальне розгортання має забезпечувати відповідність місцевим правилам управління даними. Синтетичні дані, згенеровані вчителем, повинні бути валідовані та супроводжені чіткою документацією ризиків та обмежень.

---

## Бібліографічні посилання

- **[abdullin2026sgr]** Abdullin et al. (2026). Schema-Guided Reasoning for Structured Medical Extraction.
- **[aronson2001]** Aronson, A. R. (2001). Effective mapping of biomedical text to the UMLS Metathesaurus: the MetaMap program.
- **[dong2024xgrammar]** Dong et al. (2024). XGrammar: Flexible, Efficient Grammar-Constrained Generation for Structured LLM Outputs. *arXiv:2411.15100*.
- **[ferrazzi2025converting]** Ferrazzi, P., Lavelli, A., Magnini, B. (2025). Converting Annotated Clinical Cases into Structured Case Report Forms. *BioNLP 2025*, pp. 307–318.
- **[ferrazzi2026]** Ferrazzi, P., Ghosh, S., Lavelli, A., Magnini, B. (2026). Overview of the CRF 2026 Shared Task on Clinical Case Report Forms filling. *CL4Health Workshop*.
- **[ferrazzi2026smallllms]** Ferrazzi, P., Franzin, M., Lavelli, A., Magnini, B. (2026). Small LLMs for Medical NLP: a Systematic Analysis of Few-Shot, Constraint Decoding, Fine-Tuning and Continual Pre-Training in Italian. *arXiv:2602.17475*.
- **[khattab2023]** Khattab et al. (2023). DSPy: Compiling Declarative Language Model Calls into Self-Improving Pipelines. *arXiv:2310.03714*.
- **[neumann2019]** Neumann et al. (2019). ScispaCy: Fast and Robust Models for Biomedical Natural Language Processing. *BioNLP 2019*.
- **[saab2024]** Saab et al. (2024). Capabilities of Gemini Models in Medicine. *arXiv:2404.18416*.
- **[singhal2023]** Singhal et al. (2023). Large language models encode clinical knowledge. *Nature*, 620(7972).
- **[soldaini2016]** Soldaini and Goharian (2016). QuickUMLS: a fast, unsupervised approach for medical concept extraction. *MedIR Workshop, SIGIR 2016*.
- **[suominen2013]** Suominen et al. (2013). Overview of the ShARe/CLEF eHealth Evaluation Lab 2013.
- **[uzuner2011]** Uzuner et al. (2011). 2010 i2b2/VA challenge on concepts, assertions, and relations in clinical text. *JAMIA*, 18(5).
- **[willard2023]** Willard and Louf (2023). Efficient Guided Generation for Large Language Models. *arXiv:2307.09702*.
- **[zheng2024]** Zheng et al. (2024). SGLang: Efficient Execution of Structured Language Model Programs. *arXiv:2312.07104*.

---

## Мовні ресурси (Language Resource References)

- **[DyspneaCRFTrain]** NLP-FBK. Dyspnea CRF Train Dataset. Hugging Face, 2025.
- **[DyspneaCRFDev]** NLP-FBK. Dyspnea CRF Development Dataset. Hugging Face, 2025.
- **[DyspneaCRFTest]** NLP-FBK. Dyspnea CRF Test Dataset. Hugging Face, 2026.
- **[DyspneaClinicalNotes]** NLP-FBK. Dyspnea Clinical Notes (Unannotated). Hugging Face, 2025.
